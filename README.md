<p align="center">
<img src="https://user-images.githubusercontent.com/47762020/132246961-5cd50019-8274-4822-bc91-5cafbee07927.jpg" width=25% height=25%>
</p>


## Welcome !

This repository contains the public FTC SDK for the Ultimate Goal (2020-2021) competition season.
This GitHub repository contains the source code that is used to build an Android app to control a *FIRST* Tech Challenge competition robot.

## TeamCode
The majority of our team's code can be found in TeamCode.

## How the game is played
You can watch this 6 minute video presentation to understand the game:

[![Video Presentation](https://img.youtube.com/vi/k2pgPQgHQ28/0.jpg)](https://www.youtube.com/watch?v=k2pgPQgHQ28)

## Team Awards
<p align="center">
<img src="https://user-images.githubusercontent.com/47762020/132247519-934de943-40f5-44b0-bf03-5f887861bf45.jpg" width=50% height=50%>
</p>

Our robot at the Bucharest National Championship, alongside the awards we won at that competition.

During the Ultimate Goal Season we have won the following awards:
- An invitation at the Maryland Tech Invitational (Baltimore, Maryland, USA), one of the most prestigious competitions First Tech Challenge has to offer which saw us placed Top 10 in a competition against the best and most experienced teams in the world.
- Finalist Alliance and Connect Award at the Bucharest National Championship
- First Place at 4 "Remote Scrimmage" competitions
- Collins Aerospace Innovate Award and Control Award at the Regional Championship in Russia
- Control Award at the Regional Championship in Timisoara, Romania

## Key parts of our code
Using the Intel® RealSense™ Tracking Camera T265 we have made an auto-aiming robot turret.
The Intel® RealSense™ Tracking Camera T265 utilises V-SLAM.

SLAM, or Simultaneous Localization and Mapping, is a computational problem – how does a device construct or update a map of an unknown environment while simultaneously keeping track of it’s own location within that environment? Before the days of GPS, sailors would navigate by the stars, using their movements and positions to successfully find their way across oceans. V‑SLAM uses a combination of cameras and Inertial Measurement Units (IMU) to navigate in a similar way, using visual features in the environment to track it’s way around even unknown spaces with accuracy.

Another key part is our 3-wheel-odometry setup. 

To learn more about these systems you can watch our presentation video:

[![Video Presentation](https://img.youtube.com/vi/U36CgINBMnQ/0.jpg)](https://www.youtube.com/watch?v=U36CgINBMnQ)

Or you can read the following flyer:
N/A
